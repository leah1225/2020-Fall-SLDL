{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Á¨¨‰∏ÄÈ°å [Data Preprocessing]¬∂"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ÊääÊâÄÊúâÊúâÁº∫ÂÄºÁöÑRowsÂà™Èô§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Ë≥áÊñôÊ¨Ñ‰ΩçÂêçÁ®±\n",
    "columns= ['age,', 'workclass,', 'fnlwgt,', 'education,', 'education-num,', 'marital-status,',\n",
    "          'occupation,','relationship,', 'race,', 'gender,', 'capital-gain,', 'capital-loss,',\n",
    "          'hours-per-week,', 'native-country,', 'label']\n",
    "\n",
    "#Â∞çtrain data\n",
    "dsfile = 'adult.data'\n",
    "data = open('data.csv', 'w')\n",
    "\n",
    "for col in columns:  #ÂØ´ÂÖ•column name\n",
    "    data.write(col)\n",
    "data.write('\\n')\n",
    "\n",
    "with open(dsfile, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        if '?' not in line:\n",
    "            data.write(line.replace(' ', ''))\n",
    "data.close()\n",
    "\n",
    "#Â∞çtest data\n",
    "tsfile = 'adult.test'\n",
    "test = open('test.csv', 'w')\n",
    "\n",
    "for col in columns:  #ÂØ´ÂÖ•column name\n",
    "    test.write(col)\n",
    "test.write('\\n')\n",
    "\n",
    "with open(tsfile, 'r') as f:\n",
    "    f.readline()\n",
    "    for line in f.readlines():\n",
    "        if '?' not in line:\n",
    "            line = line.replace('.', '')\n",
    "            test.write(line.replace(' ', ''))\n",
    "test.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ËÆÄÂèñÊ∏ÖÁêÜÂ•ΩÁöÑtrainÂíåtest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "tf = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dum = pd.get_dummies(df)\n",
    "test_dum = pd.get_dummies(tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ÂèñÂá∫Ê®ôÁ±§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data_dum['label_>50K']\n",
    "y_test = test_dum['label_>50K']\n",
    "\n",
    "data_dum = data_dum.drop(columns=['label_<=50K', 'label_>50K'])\n",
    "test_dum = test_dum.drop(columns=['label_<=50K', 'label_>50K'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Âà™Èô§Âá∫Áèæ‰∏çÂà∞10Ê¨°ÁöÑÁâπÂæµÂÄº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "delet_dum = data_dum.columns[np.where(np.sum(data_dum, axis = 0)<10)]\n",
    "data_dum = data_dum.drop(columns = delet_dum)\n",
    "for d in delet_dum:\n",
    "    if d in test_dum.columns:\n",
    "        test_dum = test_dum.drop(columns = d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_order = ['capital-loss', 'hours-per-week', 'capital-gain',\n",
    "       'education-num', 'age', 'fnlwgt', 'relationship_Husband',\n",
    "       'relationship_Not-in-family', 'relationship_Other-relative',\n",
    "       'relationship_Own-child', 'relationship_Unmarried',\n",
    "       'relationship_Wife', 'race_Amer-Indian-Eskimo',\n",
    "       'race_Asian-Pac-Islander', 'race_Black', 'race_Other',\n",
    "       'race_White', 'gender_Female', 'gender_Male',\n",
    "       'occupation_Adm-clerical', 'occupation_Craft-repair',\n",
    "       'occupation_Exec-managerial', 'occupation_Farming-fishing',\n",
    "       'occupation_Handlers-cleaners', 'occupation_Machine-op-inspct',\n",
    "       'occupation_Other-service', 'occupation_Priv-house-serv',\n",
    "       'occupation_Prof-specialty', 'occupation_Protective-serv',\n",
    "       'occupation_Sales', 'occupation_Tech-support',\n",
    "       'occupation_Transport-moving', 'education_10th', 'education_11th',\n",
    "       'education_12th', 'education_1st-4th', 'education_5th-6th',\n",
    "       'education_7th-8th', 'education_9th', 'education_Assoc-acdm',\n",
    "       'education_Assoc-voc', 'education_Bachelors',\n",
    "       'education_Doctorate', 'education_HS-grad', 'education_Masters',\n",
    "       'education_Preschool', 'education_Prof-school',\n",
    "       'education_Some-college', 'native-country_Cambodia',\n",
    "       'native-country_Canada', 'native-country_China',\n",
    "       'native-country_Columbia', 'native-country_Cuba',\n",
    "       'native-country_Dominican-Republic', 'native-country_Ecuador',\n",
    "       'native-country_El-Salvador', 'native-country_England',\n",
    "       'native-country_France', 'native-country_Germany',\n",
    "       'native-country_Greece', 'native-country_Guatemala',\n",
    "       'native-country_Haiti', 'native-country_Honduras',\n",
    "       'native-country_Hong', 'native-country_Hungary',\n",
    "       'native-country_India', 'native-country_Iran',\n",
    "       'native-country_Ireland', 'native-country_Italy',\n",
    "       'native-country_Jamaica', 'native-country_Japan',\n",
    "       'native-country_Laos', 'native-country_Mexico',\n",
    "       'native-country_Nicaragua',\n",
    "       'native-country_Outlying-US(Guam-USVI-etc)', 'native-country_Peru',\n",
    "       'native-country_Philippines', 'native-country_Poland',\n",
    "       'native-country_Portugal', 'native-country_Puerto-Rico',\n",
    "       'native-country_Scotland', 'native-country_South',\n",
    "       'native-country_Taiwan', 'native-country_Thailand',\n",
    "       'native-country_Trinadad&Tobago', 'native-country_United-States',\n",
    "       'native-country_Vietnam', 'native-country_Yugoslavia',\n",
    "       'workclass_Federal-gov', 'workclass_Local-gov',\n",
    "       'workclass_Private', 'workclass_Self-emp-inc',\n",
    "       'workclass_Self-emp-not-inc', 'workclass_State-gov',\n",
    "       'workclass_Without-pay', 'marital-status_Divorced',\n",
    "       'marital-status_Married-AF-spouse',\n",
    "       'marital-status_Married-civ-spouse',\n",
    "       'marital-status_Married-spouse-absent',\n",
    "       'marital-status_Never-married', 'marital-status_Separated',\n",
    "       'marital-status_Widowed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ê†πÊìöÈ°åÁõÆÁµ¶ÁöÑÈ†ÜÂ∫èÈáçÊñ∞ÊéíÂ∫è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dum = data_dum.reindex(columns=new_order)\n",
    "test_dum = test_dum.reindex(columns=new_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ê®ôÊ∫ñÂåñÈÄ£Á∫åËÆäÊï∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data_dum.columns[0:6]:\n",
    "    mean = np.mean(data_dum[col])\n",
    "    std = np.std(data_dum[col])\n",
    "    data_dum[col] = (data_dum[col]-mean)/std\n",
    "    test_dum[col] = (test_dum[col]-mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ÂØ´ÂÖ•dictionaryÂíåadult_m50k.pickleÊØîËºÉ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train match!\n",
      "x_test match!\n",
      "y_train match!\n",
      "y_test match!\n"
     ]
    }
   ],
   "source": [
    "#ÊîæÂÖ•dictionary\n",
    "\n",
    "adult50k = {}\n",
    "adult50k['x_train'] = data_dum.to_numpy()\n",
    "adult50k['y_train'] = np.array(y_train)\n",
    "adult50k['x_test'] = test_dum.to_numpy()\n",
    "adult50k['y_test'] = np.array(y_test)\n",
    "\n",
    "#ÊØîËºÉÁîüÊàêÁöÑDictionaryËàáÁî±adult_m50k.pickleËÆÄÂÖ•ÁöÑË≥áÊñô\n",
    "\n",
    "dsfile = 'adult_m50k.pickle'\n",
    "with open(dsfile, 'rb') as fh1:\n",
    "    adult50kp = pickle.load(fh1)\n",
    "\n",
    "elems = ['x_train', 'x_test', 'y_train', 'y_test']\n",
    "\n",
    "for aelem in elems:\n",
    "    cnomatch = np.sum(adult50kp[aelem] != adult50k[aelem])\n",
    "    if cnomatch == 0:\n",
    "        print(aelem, \"match!\")\n",
    "    else:\n",
    "        print(aelem, \"%d elements no match!\" % cnomatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Á¨¨‰∫åÈ°å [ROC and AUC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.848406\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "dsfile = 'adult_m50k.pickle'\n",
    "with open(dsfile, 'rb') as fh1:\n",
    "    adult50kp = pickle.load(fh1)\n",
    "    \n",
    "#train prediction model    \n",
    "c = 0.3\n",
    "lr2 = LogisticRegression(solver = 'lbfgs', C= c, max_iter = 1000)\n",
    "lr2.fit(adult50kp['x_train'], adult50kp['y_train'])\n",
    "#make prediction\n",
    "ypred = lr2.predict(adult50kp['x_test'])\n",
    "ypredprob = lr2.predict_proba(adult50kp['x_test'])\n",
    "#compute accuracy\n",
    "ncorrect = np.sum(adult50kp['y_test'] == ypred)\n",
    "accuracy_sk = ncorrect / adult50kp['y_test'].shape[0]\n",
    "print(\"Accuracy = %f\" % accuracy_sk)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Â∞áPredicted ProbabilityÂíåActual ClassÊï¥ÁêÜÊàêÂ∞çÁÖßË°®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = []\n",
    "for i in range(ypred.shape[0]):\n",
    "    table.append([ypredprob[i][1],adult50kp['y_test'][i]])\n",
    "\n",
    "#sort predprob by descending order\n",
    "table.sort(reverse = True)\n",
    "table = np.array(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ë®àÁÆóTP/FP Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.sum(adult50kp['y_test']==1)\n",
    "N = np.sum(adult50kp['y_test']==0)\n",
    "TPr = []\n",
    "FPr = []\n",
    "for i in range(len(table)):\n",
    "    threshold = table[i][0]\n",
    "    TP = np.sum((table[:,[0]] >= threshold)&(table[:,[1]]==1))\n",
    "    FP = np.sum((table[:,[0]] >= threshold)&(table[:,[1]]==0))\n",
    "    TPr.append(TP/P)\n",
    "    FPr.append(FP/N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.1 Áπ™Ë£ΩROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(FPr,TPr)\n",
    "\n",
    "#Ë®≠ÂÆöxËª∏yËª∏ÊúÄÂ§ßÊúÄÂ∞èÂÄº\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "\n",
    "#Ë®≠ÂÆöxËª∏yËª∏Ê®ôÈ°åÂêçÁ®±\n",
    "plt.xlabel(\"FP Rate\")\n",
    "plt.ylabel(\"TP Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.2 Ë®àÁÆóÁπ™Ë£ΩÂá∫ÁöÑROC CurveÁöÑAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9034897578035781\n"
     ]
    }
   ],
   "source": [
    "#‰ΩøÁî®Ê¢ØÂΩ¢Èù¢Á©çÂÖ¨ÂºèË®àÁÆóAUC\n",
    "\n",
    "TP_up = np.array(TPr[:15059].copy()) #‰∏äÂ∫ï\n",
    "TP_down = np.array(TPr[1:].copy()) #‰∏ãÂ∫ï\n",
    "\n",
    "FP_up = np.array(FPr[1:].copy())\n",
    "FP_down = np.array(FPr[:15059].copy())\n",
    "height = FP_up-FP_down\n",
    "\n",
    "area = np.sum(0.5*(TP_up + TP_down)*height)\n",
    "print('AUC:',area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Á¨¨‰∏âÈ°å [Logistic Regression with L2 Regularization]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.1 Derive the gradient and hessian matrix for the new E(w)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient is $\\nabla{E(w)} = \\Lambda w + x^T(y - t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hessian matrix is $\\nabla\\nabla{E(w)} = x^TRx+ \\Lambda, R = y(1-y) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.2 Create your mylogistic_l2 class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mylogistic_l2():\n",
    "    def __init__(self, reg_vec, max_iter = 100, tol = 1e-5, add_intercept = True):\n",
    "        self.reg_vec = reg_vec\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.add_intercept = add_intercept\n",
    "        \n",
    "    def gradient(self, x, y):\n",
    "        alpha = np.dot(x, self.w)\n",
    "        y_n = 1/(1+np.exp(-alpha))\n",
    "        gradient = np.dot(x.T, (y_n-y)) + np.dot(self.reg_vec, self.w)\n",
    "        return gradient\n",
    "    \n",
    "    def hessian(self, x, y):\n",
    "        alpha = np.dot(x, self.w)\n",
    "        y_n = 1/(1+np.exp(-alpha))\n",
    "        R = np.diag(y_n * (1 - y_n))\n",
    "        hessian = np.dot(np.dot(x.T, R), x) + self.reg_vec\n",
    "        return hessian\n",
    "\n",
    "    def fit(self, x, y, verbal = False):\n",
    "        \n",
    "        if self.add_intercept:\n",
    "            \n",
    "            #add a column of ones to the end of X_train\n",
    "            add_col = np.ones((x.shape[0], 1))\n",
    "            x = np.concatenate([x, add_col], axis=1)\n",
    "            \n",
    "        #initialize w\n",
    "        b = np.mean(np.diag(self.reg_vec))   \n",
    "        a = (np.dot(x.T,x)+b*(np.eye(x.shape[1]))) \n",
    "        a_inv = np.linalg.inv(a)\n",
    "        self.w = np.dot(a_inv, np.dot(x.T, y))\n",
    "        \n",
    "        #start iteration\n",
    "        for i in range(self.max_iter):\n",
    "            \n",
    "            #original error\n",
    "            alpha = np.dot(x, self.w)\n",
    "            y_n = 1/(1+np.exp(-alpha))\n",
    "            err = np.sum(y*np.log(y_n) + (1 - y)*np.log(1-y_n))\n",
    "            err_old = 0.5*np.dot(np.dot(self.w.T, self.reg_vec), self.w) - err\n",
    "            \n",
    "            #new w\n",
    "            g = self.gradient(x, y)\n",
    "            h = self.hessian(x, y)\n",
    "            self.w = self.w - np.dot(np.linalg.inv(h), g)\n",
    "            \n",
    "            #new error\n",
    "            alpha = np.dot(x, self.w)\n",
    "            y_n = 1/(1+np.exp(-alpha))\n",
    "            err = np.sum(y*np.log(y_n) + (1 - y)*np.log(1-y_n))\n",
    "            err_new = 0.5*np.dot(np.dot(self.w.T, self.reg_vec), self.w) - err\n",
    "            \n",
    "            improve = abs(err_old - err_new)\n",
    "            if improve < self.tol:\n",
    "                break\n",
    "        \n",
    "    def predict(self, x):\n",
    "        pred = np.dot(x, self.w.T)\n",
    "        pred = np.where(pred >= 0.5, 1, 0)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsfile = 'adult_m50k.pickle'\n",
    "with open(dsfile, 'rb') as fh1:\n",
    "    adult50kp = pickle.load(fh1)\n",
    "x_train = adult50kp['x_train']\n",
    "y_train = adult50kp['y_train']\n",
    "x_test = adult50kp['x_test']\n",
    "y_test = adult50kp['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1: lambda = 1 for all coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize lambda vector\n",
    "lambda_vec = np.eye(x_train.shape[1])\n",
    "\n",
    "#adding a column of 0s to lambda vector\n",
    "new_col = np.zeros((lambda_vec.shape[0], 1))\n",
    "lambda_vec = np.concatenate([lambda_vec, new_col], axis=1) \n",
    "\n",
    "#adding a row to lambda vector\n",
    "new_row = np.zeros((1, lambda_vec.shape[1]))\n",
    "new_row[0][new_row.shape[1]-1] = 1\n",
    "lambda_vec = np.concatenate([lambda_vec, new_row], axis=0)\n",
    "\n",
    "logic1 = mylogistic_l2(reg_vec = lambda_vec, max_iter = 100, tol = 1e-5, add_intercept = True)\n",
    "logic1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### show the learned  ùë§ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.58310749e-01  3.52951378e-01  2.33390152e+00  7.51145211e-01\n",
      "  3.33524430e-01  7.92368680e-02 -2.59305992e-01 -3.31059192e-02\n",
      " -8.02092312e-01 -1.16328375e+00 -1.57480268e-01  1.06974336e+00\n",
      " -6.33846058e-01  1.16732409e-01 -2.31567381e-01 -5.17122207e-01\n",
      " -7.97216465e-02 -1.09949780e+00 -2.46027086e-01  6.19694928e-02\n",
      "  1.26685884e-01  8.62656059e-01 -9.18352843e-01 -6.21226177e-01\n",
      " -2.00740224e-01 -7.51600981e-01 -1.61011588e+00  5.75820911e-01\n",
      "  6.48995283e-01  3.53741434e-01  7.17218474e-01 -2.84494743e-02\n",
      " -9.54820746e-04 -1.96540899e-01 -1.46351640e-01  6.26946275e-01\n",
      "  4.48207080e-01  2.45945819e-02  4.69223657e-02 -4.91067746e-01\n",
      " -2.03035424e-01 -1.63303680e-01 -1.76623501e-02 -1.11328323e-01\n",
      " -9.94618240e-02 -1.17391916e+00  1.80702678e-01 -6.92720004e-02\n",
      "  9.76496905e-01  4.60988601e-01 -4.95440416e-01 -1.27203531e+00\n",
      "  4.86772406e-01 -8.98963733e-01 -6.00542591e-02 -3.50848853e-01\n",
      "  4.32815220e-01  5.94120150e-01  5.82151924e-01 -6.20962283e-01\n",
      " -5.97480378e-02  9.29035250e-02 -1.51892101e-01 -5.38528893e-03\n",
      "  3.41609087e-02 -2.89088236e-01  1.56053911e-01  4.95401243e-01\n",
      "  8.90942264e-01  1.49151436e-01  3.42484779e-01 -3.13312160e-01\n",
      " -3.55939108e-01 -3.62494608e-01 -6.67247475e-01 -4.08831130e-01\n",
      "  4.47489832e-01  1.37768931e-01  1.41351233e-01 -1.16015421e-01\n",
      " -5.61032710e-02 -9.34583042e-01 -2.92596523e-02 -2.99012958e-01\n",
      " -1.50511251e-01  3.52331870e-01 -7.85846536e-01  5.80200207e-01\n",
      "  4.97042311e-01 -1.90320740e-01 -3.47717245e-04  1.74993805e-01\n",
      " -4.88202695e-01 -3.12259616e-01 -1.02643023e+00 -7.22310834e-01\n",
      "  1.44672469e+00  1.15520745e+00 -6.80202902e-01 -1.21195630e+00\n",
      " -7.98338505e-01 -5.34648484e-01 -1.34552489e+00]\n"
     ]
    }
   ],
   "source": [
    "print(logic1.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a column of 1s to testing data\n",
    "new_col = np.ones((x_test.shape[0], 1))\n",
    "x_test_with_intercp = np.concatenate([x_test.copy(), new_col], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8414342629482072\n"
     ]
    }
   ],
   "source": [
    "ypred = logic1.predict(x_test_with_intercp)\n",
    "accu = np.sum(ypred == y_test)/y_test.shape[0]\n",
    "print('Accuracy: ', accu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2: lambda = 1 for all but the intercept, no regularization for intercept term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize lambda vector\n",
    "lambda_vec = np.eye(x_train.shape[1])\n",
    "\n",
    "#adding a column of 0s to lambda vector\n",
    "new_col = np.zeros((lambda_vec.shape[0], 1))\n",
    "lambda_vec = np.concatenate([lambda_vec, new_col], axis=1) \n",
    "\n",
    "#adding a row to lambda vector\n",
    "new_row = np.zeros((1, lambda_vec.shape[1]))\n",
    "lambda_vec = np.concatenate([lambda_vec, new_row], axis=0)\n",
    "\n",
    "logic2 = mylogistic_l2(reg_vec = lambda_vec, max_iter = 100, tol = 1e-5, add_intercept = True)\n",
    "logic2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### show the learned  ùë§ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.25833063  0.35307341  2.33348255  0.7378757   0.33385106  0.07926886\n",
      " -0.04219572  0.1998764  -0.58360968 -0.93671312  0.07548468  1.28715744\n",
      " -0.37140327  0.39422898  0.04305748 -0.26147348  0.19559029 -0.42695771\n",
      "  0.42695771  0.16424528  0.22840772  0.96472553 -0.81743779 -0.52074423\n",
      " -0.09910239 -0.64944042 -1.55235098  0.6786798   0.75066429  0.45541098\n",
      "  0.81857112  0.07308911  0.0728464  -0.11752644 -0.06282948  0.67242506\n",
      "  0.5040869   0.08799091  0.11435013 -0.38483984 -0.10196309 -0.05145374\n",
      "  0.10741777 -0.01997934  0.01717544 -1.16567808  0.30082277  0.02715464\n",
      "  1.00831207  0.50210397 -0.45756662 -1.24002555  0.52780939 -0.86832688\n",
      " -0.02771494 -0.31412701  0.47343435  0.62981111  0.62405658 -0.5867506\n",
      " -0.0296708   0.12414401 -0.14376238  0.02434194  0.0621604  -0.24843986\n",
      "  0.19459429  0.52620501  0.93165615  0.18707696  0.37950109 -0.28749402\n",
      " -0.31137357 -0.33290534 -0.65117786 -0.38160106  0.48879121  0.17662205\n",
      "  0.17410342 -0.07343502 -0.0314651  -0.89846776  0.00653561 -0.27232555\n",
      " -0.12442075  0.39697177 -0.75318727  0.61067658  0.70544004  0.01789988\n",
      "  0.2090388   0.382747   -0.2795817  -0.10453082 -0.9310132  -0.52642474\n",
      "  1.61398954  1.36735898 -0.49235221 -1.01493649 -0.60567591 -0.34195917\n",
      " -3.17508577]\n"
     ]
    }
   ],
   "source": [
    "print(logic2.w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8411686586985392\n"
     ]
    }
   ],
   "source": [
    "ypred = logic2.predict(x_test_with_intercp)\n",
    "accu = np.sum(ypred == y_test)/y_test.shape[0]\n",
    "print('Accuracy: ', accu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 3: lambda = 1 for numerical-valued features, lambda = 0.5 for binary-valued features, no regularization for intercept term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize lambda vector\n",
    "lambda_vec = np.eye(x_train.shape[1])\n",
    "for i in range(lambda_vec.shape[0]):\n",
    "    if i > 5:\n",
    "        lambda_vec[i][i] = 0.5\n",
    "\n",
    "#adding a column of 0s to lambda vector\n",
    "new_col = np.zeros((lambda_vec.shape[0], 1))\n",
    "lambda_vec = np.concatenate([lambda_vec, new_col], axis=1) \n",
    "\n",
    "#adding a row to lambda vector\n",
    "new_row = np.zeros((1, lambda_vec.shape[1]))\n",
    "lambda_vec = np.concatenate([lambda_vec, new_row], axis=0)\n",
    "\n",
    "logic3 = mylogistic_l2(reg_vec = lambda_vec, max_iter = 100, tol = 1e-5, add_intercept = True)\n",
    "logic3.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### show the learned  ùë§ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.25851661  0.3533387   2.33562764  0.7825921   0.33439916  0.07940036\n",
      " -0.08347988  0.23309134 -0.59278098 -0.9224849   0.11139573  1.25425869\n",
      " -0.38299462  0.41291781  0.04136013 -0.26411462  0.19283128 -0.42890321\n",
      "  0.42890321  0.23635122  0.30021361  1.03810521 -0.75216086 -0.4534137\n",
      " -0.02691157 -0.5825269  -2.00075382  0.75127891  0.82696617  0.52830705\n",
      "  0.89488994  0.14510375  0.18253094 -0.02583999  0.00991404  0.89862004\n",
      "  0.68517002  0.23294385  0.24519931 -0.38363083 -0.08029608 -0.06493444\n",
      "  0.0453608   0.03743376 -0.01295908 -2.09374319  0.25763304  0.06659781\n",
      "  1.18748312  0.55059265 -0.47576613 -1.45842154  0.5822242  -1.0627833\n",
      " -0.00957211 -0.31704572  0.52485137  0.73044517  0.67457228 -0.63624179\n",
      " -0.00967268  0.17339113 -0.2364757   0.0375474   0.10120874 -0.24679341\n",
      "  0.23800627  0.64228457  1.00567032  0.23258941  0.42267607 -0.35336167\n",
      " -0.29178766 -0.38125401 -0.96291964 -0.45007954  0.512985    0.22019382\n",
      "  0.22640627 -0.04989103 -0.01836864 -0.95953334  0.01656804 -0.32741555\n",
      " -0.14011404  0.42856024 -0.84476926  0.75121645  0.76670733  0.07638783\n",
      "  0.26824615  0.44314098 -0.2205815  -0.04631789 -1.28758289 -0.57187068\n",
      "  1.82502287  1.39622511 -0.54691696 -1.05894077 -0.65551468 -0.38800489\n",
      " -3.36269033]\n"
     ]
    }
   ],
   "source": [
    "print(logic3.w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8413678618857902\n"
     ]
    }
   ],
   "source": [
    "ypred = logic3.predict(x_test_with_intercp)\n",
    "accu = np.sum(ypred == y_test)/y_test.shape[0]\n",
    "print('Accuracy: ', accu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.3 Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_subtrain, x_tune, y_subtrain, y_tune = train_test_split(x_train, y_train, test_size = 0.1)\n",
    "\n",
    "#adding intercrpt\n",
    "new_col = np.ones((x_tune.shape[0], 1))\n",
    "x_tune = np.concatenate([x_tune, new_col], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13362726, 0.11644891, 0.99743395, 0.1912213 , 0.92171088])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridset = np.random.rand(5)\n",
    "gridset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conduct grid search with the constraint that  ùëé1=ùëé2. Record the best value  ùëé‚àó1  and  ùëé‚àó2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1 = a2 = 0.1336272619630453\n",
      "a1 = a2 = 0.11644890863104884\n",
      "a1 = a2 = 0.9974339501357573\n",
      "a1 = a2 = 0.19122130453668085\n",
      "a1 = a2 = 0.9217108765806664\n",
      "Optimal lambda for continuous-valued = 0.1336272619630453\n",
      "Optimal lambda for binary-valued = 0.1336272619630453\n"
     ]
    }
   ],
   "source": [
    "opt_a1 = None\n",
    "opt_a2 = None\n",
    "opt_accuracy = 0\n",
    "for i in gridset:\n",
    "    logic = mylogistic_l2(reg_vec = np.diag([i]*6 + [i]*96 + [0]), max_iter = 100, tol = 1e-5, add_intercept = True)\n",
    "    print(\"a1 = a2 =\", i)\n",
    "    logic.fit(x_subtrain, y_subtrain)\n",
    "    ypred = logic.predict(x_tune)\n",
    "    accu = np.sum(ypred == y_tune)/y_tune.shape[0]\n",
    "    if accu > opt_accuracy:\n",
    "        opt_accuracy = accu\n",
    "        opt_a1 = i\n",
    "        opt_a2 = i\n",
    "print(\"Optimal lambda for continuous-valued =\", opt_a1)\n",
    "print(\"Optimal lambda for binary-valued =\", opt_a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix  ùëé1=ùëé‚àó1 , and search  ùëé2  for the best value, call the result the new  ùëé‚àó2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2 = 0.1336272619630453\n",
      "a2 = 0.11644890863104884\n",
      "a2 = 0.9974339501357573\n",
      "a2 = 0.19122130453668085\n",
      "a2 = 0.9217108765806664\n",
      "Optimal lambda for continuous-valued = 0.1336272619630453\n",
      "Optimal lambda for binary-valued = 0.1336272619630453\n"
     ]
    }
   ],
   "source": [
    "opt_a2 = None\n",
    "opt_accuracy = 0\n",
    "for i in gridset:\n",
    "    logic = mylogistic_l2(reg_vec = np.diag([opt_a1]*6 + [i]*96 + [0]), max_iter = 100, tol = 1e-5, add_intercept = True)\n",
    "    print(\"a2 =\", i)\n",
    "    logic.fit(x_subtrain, y_subtrain)\n",
    "    ypred = logic.predict(x_tune)\n",
    "    accu = np.sum(ypred == y_tune)/y_tune.shape[0]\n",
    "    if accu > opt_accuracy:\n",
    "        opt_accuracy = accu\n",
    "        opt_a2 = i\n",
    "print(\"Optimal lambda for continuous-valued =\", opt_a1)\n",
    "print(\"Optimal lambda for binary-valued =\", opt_a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix  ùëé2=ùëé‚àó2 , and search  ùëé1  for the best value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1 = 0.1336272619630453\n",
      "a1 = 0.11644890863104884\n",
      "a1 = 0.9974339501357573\n",
      "a1 = 0.19122130453668085\n",
      "a1 = 0.9217108765806664\n",
      "Optimal lambda for continuous-valued = 0.9974339501357573\n",
      "Optimal lambda for binary-valued = 0.1336272619630453\n"
     ]
    }
   ],
   "source": [
    "opt_a1 = None\n",
    "opt_accuracy = 0\n",
    "for i in gridset:\n",
    "    logic = mylogistic_l2(reg_vec = np.diag([i]*6 + [opt_a2]*96 + [0]), max_iter = 100, tol = 1e-5, add_intercept = True)\n",
    "    print(\"a1 =\", i)\n",
    "    logic.fit(x_subtrain, y_subtrain)\n",
    "    ypred = logic.predict(x_tune)\n",
    "    accu = np.sum(ypred == y_tune)/y_tune.shape[0]\n",
    "    if accu > opt_accuracy:\n",
    "        opt_accuracy = accu\n",
    "        opt_a1 = i\n",
    "print(\"Optimal lambda for continuous-valued =\", opt_a1)\n",
    "print(\"Optimal lambda for binary-valued =\", opt_a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report the selected  ùëé1  and  ùëé2 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal lambda for continuous-valued = 0.9974339501357573\n",
      "Optimal lambda for binary-valued = 0.1336272619630453\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal lambda for continuous-valued =\", opt_a1)\n",
    "print(\"Optimal lambda for binary-valued =\", opt_a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model using the selected hyper-parameters, and report the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8413014608233732\n"
     ]
    }
   ],
   "source": [
    "logic = mylogistic_l2(reg_vec = np.diag([opt_a1]*6 + [opt_a2]*96 + [0]), max_iter = 100, tol = 1e-5, add_intercept = True)\n",
    "logic.fit(x_train, y_train)\n",
    "ypred = logic.predict(x_test_with_intercp)\n",
    "accu = np.sum(ypred == y_test)/y_test.shape[0]\n",
    "print('Accuracy: ', accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.25880729  0.35347585  2.34798977  0.88473866  0.33486562  0.07944389\n",
      " -0.13190281  0.26632723 -0.58817073 -0.90727567  0.14753355  1.21348842\n",
      " -0.39228439  0.42773828  0.04010673 -0.26659723  0.19103661 -0.43070293\n",
      "  0.43070293  0.43662975  0.50008915  1.23988025 -0.55272272 -0.25683841\n",
      "  0.17331522 -0.38662173 -2.75211393  0.95219392  1.03100486  0.72949181\n",
      "  1.09885274  0.34562143  0.50240004  0.25300316  0.24946691  1.42481491\n",
      "  1.14225498  0.63334254  0.60951915 -0.30746183  0.03804537 -0.02638559\n",
      " -0.03324436  0.23669137 -0.01393067 -5.15478797  0.22081875  0.22545324\n",
      "  1.37547852  0.61391287 -0.46773047 -1.6951188   0.65041938 -1.30850283\n",
      "  0.03184167 -0.29723628  0.5908336   0.84501503  0.73933769 -0.65972532\n",
      "  0.03507726  0.24703125 -0.48049351  0.07461208  0.16689015 -0.22258827\n",
      "  0.30041675  0.77752663  1.08903371  0.29707793  0.48301124 -0.40750506\n",
      " -0.24119787 -0.41361164 -1.71668528 -0.50667759  0.55537427  0.28128652\n",
      "  0.29938076 -0.00591688  0.02089332 -0.9873749   0.04979057 -0.36579239\n",
      " -0.13523672  0.4773811  -0.91200595  0.91579086  0.89846728  0.20492844\n",
      "  0.39733422  0.57322987 -0.09236599  0.08230345 -2.06389728 -0.61712487\n",
      "  2.0259807   1.43287583 -0.60073511 -1.10300778 -0.7045399  -0.43344887\n",
      " -3.88294286]\n"
     ]
    }
   ],
   "source": [
    "print(logic.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.47864864864864864 recall: 0.7934587813620072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[10899,  1929],\n",
       "       [  461,  1771]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "print(\"Precision:\", precision_score(ypred, y_test), \"recall:\", recall_score(ypred, y_test))\n",
    "confusion_matrix(ypred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.4 Use sklearn.linear_model.LogisticRegression to train and test the model (including hyperparameter tuning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9217108765806664\n"
     ]
    }
   ],
   "source": [
    "opt_c = None\n",
    "opt_accuracy = 0\n",
    "for i in gridset:\n",
    "    LR = LogisticRegression(penalty = \"l2\", tol = 1e-5, C = i, max_iter = 1000, fit_intercept = True )\n",
    "    LR.fit(x_subtrain, y_subtrain)\n",
    "    ypred = LR.predict(x_tune)\n",
    "    acc = accuracy_score(y_tune, ypred)\n",
    "    if acc > opt_accuracy:\n",
    "        opt_c = i\n",
    "print(opt_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8413014608233732\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression(penalty = \"l2\", tol = 1e-5, C = opt_c, max_iter = 1000, fit_intercept = True )\n",
    "LR.fit(x_train, y_train)\n",
    "ypred = LR.predict(x_test)\n",
    "acc = accuracy_score(y_test, ypred)\n",
    "print('Accuracy: ', accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.25828456  0.35301932  2.33203401  0.73328968  0.33377775  0.07923262\n",
      "  -0.03589625  0.19530229 -0.58045692 -0.93827702  0.07032446  1.2920917\n",
      "  -0.36903526  0.39166526  0.0439339  -0.26008953  0.19661389 -0.42508258\n",
      "   0.42817084  0.15845781  0.22251602  0.95867487 -0.82205164 -0.52538937\n",
      "  -0.10470656 -0.65469216 -1.5004167   0.67272478  0.7440533   0.44946406\n",
      "   0.81208938  0.06723744  0.06364468 -0.12477356 -0.06769687  0.65110372\n",
      "   0.48693405  0.07550876  0.10318655 -0.38290335 -0.10219957 -0.04810166\n",
      "   0.11544973 -0.02395705  0.02217618 -1.09713934  0.30682867  0.02502733\n",
      "   0.98499855  0.49468144 -0.45354364 -1.21277821  0.51983186 -0.84607083\n",
      "  -0.02972627 -0.31379969  0.46637942  0.61510957  0.61689157 -0.57863328\n",
      "  -0.03188859  0.11861458 -0.13597049  0.02286738  0.05757763 -0.24800648\n",
      "   0.19012406  0.51210953  0.91889244  0.1821726   0.3730415  -0.27871947\n",
      "  -0.31336439 -0.32696154 -0.61188872 -0.3730093   0.48662555  0.17224495\n",
      "   0.16800242 -0.07498203 -0.03289698 -0.88867818  0.00554168 -0.26501134\n",
      "  -0.12195854  0.39299506 -0.73779405  0.59411554  0.69776819  0.0106558\n",
      "   0.20163806  0.37517635 -0.28690731 -0.11173641 -0.88350642 -0.51889408\n",
      "   1.58195885  1.36394639 -0.48409862 -1.00763082 -0.59775834 -0.33443513]]\n"
     ]
    }
   ],
   "source": [
    "print(LR.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6035135135135136 recall: 0.7299771167048055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[10534,  1467],\n",
       "       [  826,  2233]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Precision:\", precision_score(ypred, y_test), \"recall:\", recall_score(ypred, y_test))\n",
    "confusion_matrix(ypred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the estimated parameters and test accuracy with those from your own models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ‰ΩøÁî®sklearnÁöÑlogistic regressionÊâÄË®ìÁ∑¥ÁöÑÊ®°ÂûãÊ∫ñÁ¢∫ÁéáÁõ∏ÂêåÔºåÈÉΩÊòØ84.13ÔºÖ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ÂæûprecisionÂíårecall‰æÜÁúãÔºåsklearnÁöÑlogistic regressionÊâÄË®ìÁ∑¥Âá∫‰æÜÁöÑÊ®°ÂûãÂú®precisionÊØîËá™Â∑±ÊâãÂàªÁöÑÂ•ΩÔºõ‰ΩÜÊòØÂú®recallÁöÑÈÉ®ÂàÜÊòØÊâãÂàªÁöÑË°®ÁèæËºÉÂ•Ω"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Âæûestimated parameters‰æÜÁúãÔºåÂÖ©ÂÄãÊ®°ÂûãÂú®ÈÄ£Á∫åËÆäÊï∏ÁöÑÂèÉÊï∏ÂÄºÂæàÊé•ËøëÔºåÂú®È°ûÂà•ËÆäÁöÑÂèÉÊï∏Â∑ÆÁï∞ËºÉÂ§ß"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
