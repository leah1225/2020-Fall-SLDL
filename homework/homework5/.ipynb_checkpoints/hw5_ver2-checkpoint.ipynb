{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "znDw87yyAN90"
   },
   "outputs": [],
   "source": [
    "# load packages\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, utils\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "\n",
    "labels = ['blazer', 'cardigan', 'coat', 'jacket']\n",
    "train_num = {}\n",
    "total = 0\n",
    "\n",
    "for i in range(4):\n",
    "    basepath = os.path.join(\"photos/train\", labels[i], \"*.jpg\")\n",
    "    cand_fn = glob.glob(basepath)\n",
    "    n = 0\n",
    "    for afn in cand_fn:    \n",
    "        n += 1\n",
    "        total += 1\n",
    "    train_num[labels[i]] = n\n",
    "train_num['total'] = total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "test_num = {}\n",
    "total = 0\n",
    "\n",
    "for i in range(4):\n",
    "    basepath = os.path.join(\"photos/test\", labels[i], \"*.jpg\")\n",
    "    cand_fn = glob.glob(basepath)\n",
    "    n = 0\n",
    "    for afn in cand_fn:    \n",
    "        n += 1\n",
    "        total += 1\n",
    "    test_num[labels[i]] = n\n",
    "test_num['total'] = total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid\n",
    "\n",
    "valid_num = {}\n",
    "total = 0\n",
    "\n",
    "for i in range(4):\n",
    "    basepath = os.path.join(\"photos/valid\", labels[i], \"*.jpg\")\n",
    "    cand_fn = glob.glob(basepath)\n",
    "    n = 0\n",
    "    for afn in cand_fn:    \n",
    "        n += 1\n",
    "        total += 1\n",
    "    valid_num[labels[i]] = n\n",
    "valid_num['total'] = total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "total photo number: 1041\n",
      "blazer :\n",
      "number = 97\n",
      "ratio =  0.09317963496637849\n",
      "cardigan :\n",
      "number = 237\n",
      "ratio =  0.2276657060518732\n",
      "coat :\n",
      "number = 296\n",
      "ratio =  0.28434197886647455\n",
      "jacket :\n",
      "number = 411\n",
      "ratio =  0.39481268011527376\n",
      "\n",
      "\n",
      "Test:\n",
      "total photo number: 146\n",
      "blazer :\n",
      "number = 9\n",
      "ratio =  0.06164383561643835\n",
      "cardigan :\n",
      "number = 42\n",
      "ratio =  0.2876712328767123\n",
      "coat :\n",
      "number = 43\n",
      "ratio =  0.2945205479452055\n",
      "jacket :\n",
      "number = 52\n",
      "ratio =  0.3561643835616438\n",
      "\n",
      "\n",
      "Valid:\n",
      "total photo number: 105\n",
      "blazer :\n",
      "number = 7\n",
      "ratio =  0.06666666666666667\n",
      "cardigan :\n",
      "number = 36\n",
      "ratio =  0.34285714285714286\n",
      "coat :\n",
      "number = 27\n",
      "ratio =  0.2571428571428571\n",
      "jacket :\n",
      "number = 35\n",
      "ratio =  0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "# 列出train, valid, test的總照片數，以及各類別的照片數與比率\n",
    "\n",
    "print('Train:')\n",
    "print('total photo number:', train_num['total'])\n",
    "for label in labels:\n",
    "    print(label, ':') \n",
    "    print('number =',train_num[label])\n",
    "    print('ratio = ',train_num[label]/train_num['total'])\n",
    "    \n",
    "print('\\n')\n",
    "\n",
    "print('Test:')\n",
    "print('total photo number:', test_num['total'])\n",
    "for label in labels:\n",
    "    print(label, ':') \n",
    "    print('number =',test_num[label])\n",
    "    print('ratio = ',test_num[label]/test_num['total'])\n",
    "    \n",
    "print('\\n')\n",
    "\n",
    "print('Valid:')\n",
    "print('total photo number:', valid_num['total'])\n",
    "for label in labels:\n",
    "    print(label, ':') \n",
    "    print('number =',valid_num[label])\n",
    "    print('ratio = ',valid_num[label]/valid_num['total'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根據train和valid的資料數量比較，推測準確率的大小應該為：jacket > coat > cardigan > blazer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data (using colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jgdSq9EdAdlo",
    "outputId": "6ec94717-96fa-4253-e4fc-2369c319174a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JEXbh9uSCZT3"
   },
   "outputs": [],
   "source": [
    "train = torchvision.datasets.ImageFolder('/content/drive/MyDrive/photos/train',transform = transforms.Compose([transforms.Resize(256),\n",
    "                                                                                                               transforms.CenterCrop(224),\n",
    "                                                                                                               transforms.RandomHorizontalFlip(),\n",
    "                                                                                                               transforms.RandomRotation(20),\n",
    "                                                                                                               transforms.ToTensor(),\n",
    "                                                                                                               transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nQ5wN-D-C72Z"
   },
   "outputs": [],
   "source": [
    "test = torchvision.datasets.ImageFolder('/content/drive/MyDrive/photos/test', transform = transforms.Compose([transforms.Resize(256),\n",
    "                                                                                                              transforms.CenterCrop(224),\n",
    "                                                                                                              transforms.ToTensor(),\n",
    "                                                                                                              transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WNRLspa_D03V"
   },
   "outputs": [],
   "source": [
    "valid = torchvision.datasets.ImageFolder('/content/drive/MyDrive/photos/valid', transform = transforms.Compose([transforms.Resize(256),\n",
    "                                                                                                                transforms.CenterCrop(224),\n",
    "                                                                                                                transforms.ToTensor(),\n",
    "                                                                                                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hAn2n7TcD9ih"
   },
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train, batch_size = 32, shuffle=True, num_workers=0)\n",
    "validloader = torch.utils.data.DataLoader(valid, batch_size = 32, shuffle=True, num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(test, batch_size = 1, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "woxLtHl6nweY"
   },
   "source": [
    "# Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bZxOvZ6Un2VK"
   },
   "outputs": [],
   "source": [
    "def valid(model, loss_fn = torch.nn.CrossEntropyLoss()):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    sum_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(validloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            sum_loss += loss\n",
    "    \n",
    "    return sum_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "jAeYdIHMn22D"
   },
   "outputs": [],
   "source": [
    "# 除了準確率還要補上Confusion Matrix, 與Per-class Accuracy\n",
    "def test(model, loss_fn = torch.nn.CrossEntropyLoss()):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_true = np.zeros(146)\n",
    "    y_pred = np.zeros(146)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # 取得分最高的那一類\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum()\n",
    "            y_true[batch_idx] = targets.item()\n",
    "            y_pred[batch_idx] = predicted.item()\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print('Accuracy of the network on the 146 test images: %d %%' % (100 * correct / total))\n",
    "    print('Confusion Matrix :')\n",
    "    print(cm)\n",
    "    print('Per-class Accuracy :', cm.diagonal()/cm.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_euvOJ9Qn3F8"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn = torch.nn.CrossEntropyLoss()):\n",
    "    \n",
    "    nepoch = 200\n",
    "    patient = 20\n",
    "    \n",
    "    best_valid_loss = float(\"inf\")\n",
    "    best_state = dict()\n",
    "    step_count = 0\n",
    "    best_step_count = 0\n",
    "    stop_training = False\n",
    "    \n",
    "    for epoch_id in range(0, nepoch):\n",
    "      \n",
    "        if stop_training:\n",
    "            break\n",
    "            \n",
    "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "            model.train()\n",
    "            \n",
    "            step_count += 1\n",
    "            \n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = loss_fn(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        # calculate valid loss\n",
    "        valid_loss = valid(model)\n",
    "            \n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            best_step_count = step_count\n",
    "            best_state = {'model': model.state_dict(),\n",
    "                          'loss': valid_loss,\n",
    "                          'step_count': step_count,}\n",
    "            \n",
    "        if step_count > (best_step_count + patient):\n",
    "            stop_training = True\n",
    "    \n",
    "    #model.load_state_dict(best_state['model'])\n",
    "    print('lowest valid loss =', best_state['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TjDW87X6UQDU"
   },
   "outputs": [],
   "source": [
    "def train_test(model, optimizer, loss_fn = torch.nn.CrossEntropyLoss()):\n",
    "    \n",
    "    nepoch = 200\n",
    "    patient = 20\n",
    "    \n",
    "    best_valid_loss = float(\"inf\")\n",
    "    best_state = dict()\n",
    "    step_count = 0\n",
    "    best_step_count = 0\n",
    "    stop_training = False\n",
    "    \n",
    "    for epoch_id in range(0, nepoch):\n",
    "      \n",
    "        #print(epoch_id)\n",
    "        if stop_training:\n",
    "            break\n",
    "            \n",
    "        for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "            model.train()\n",
    "            \n",
    "            step_count += 1\n",
    "            \n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = loss_fn(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        # calculate valid loss\n",
    "        valid_loss = valid(model)\n",
    "        \n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            best_step_count = step_count\n",
    "            best_state = {'model': model.state_dict(),\n",
    "                          'loss': valid_loss,\n",
    "                          'step_count': step_count,}\n",
    "        \n",
    "        if step_count > (best_step_count + patient):\n",
    "                stop_training = True\n",
    "                break\n",
    "    \n",
    "    model.load_state_dict(best_state['model'])\n",
    "    test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LTVJThA0Mygi"
   },
   "source": [
    "# Q2. pretrained=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rIe1nnrnokGb",
    "outputId": "4f6c04ac-daee-4d4a-953e-abc4ca474733"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V3XZY_9aLfTF",
    "outputId": "1895fea6-0cde-4369-e8a9-e0a0b346444e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate = 1e-05\n",
      "lowest valid loss = tensor(5.5808, device='cuda:0')\n",
      "learning rate = 5e-05\n",
      "lowest valid loss = tensor(5.3007, device='cuda:0')\n",
      "learning rate = 9e-05\n",
      "lowest valid loss = tensor(5.4500, device='cuda:0')\n",
      "learning rate = 0.0001\n",
      "lowest valid loss = tensor(5.2862, device='cuda:0')\n",
      "learning rate = 0.0005\n",
      "lowest valid loss = tensor(5.1034, device='cuda:0')\n",
      "learning rate = 0.0009\n",
      "lowest valid loss = tensor(4.8244, device='cuda:0')\n",
      "learning rate = 0.001\n",
      "lowest valid loss = tensor(4.9529, device='cuda:0')\n",
      "learning rate = 0.005\n",
      "lowest valid loss = tensor(3.4703, device='cuda:0')\n",
      "learning rate = 0.009\n",
      "lowest valid loss = tensor(2.7666, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# tuning hyperparameter for SGD\n",
    "\n",
    "learning_rate = [0.00001, 0.00005, 0.00009, 0.0001, 0.0005, 0.0009, 0.001, 0.005, 0.009]\n",
    "for lr in learning_rate:\n",
    "    model_1 = torchvision.models.resnet50(pretrained=True)\n",
    "    fc_features = model_1.fc.in_features\n",
    "    model_1.fc = torch.nn.Linear(fc_features, 4)\n",
    "    model_1 = model_1.to(device)\n",
    "    optimizer = torch.optim.SGD(model_1.parameters(), lr=lr, momentum=0, weight_decay = 0)\n",
    "    print('learning rate =', lr)\n",
    "    train(model_1, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u69MTWCak2N5",
    "outputId": "6c27dba2-d588-4d57-e2c8-9e0f31f93c76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate = 1e-05\n",
      "lowest valid loss = tensor(2.4833, device='cuda:0')\n",
      "learning rate = 2e-05\n",
      "lowest valid loss = tensor(2.6959, device='cuda:0')\n",
      "learning rate = 3e-05\n",
      "lowest valid loss = tensor(2.4150, device='cuda:0')\n",
      "learning rate = 4e-05\n",
      "lowest valid loss = tensor(2.5379, device='cuda:0')\n",
      "learning rate = 5e-05\n",
      "lowest valid loss = tensor(2.2889, device='cuda:0')\n",
      "learning rate = 6e-05\n",
      "lowest valid loss = tensor(2.8579, device='cuda:0')\n",
      "learning rate = 7e-05\n",
      "lowest valid loss = tensor(2.3606, device='cuda:0')\n",
      "learning rate = 8e-05\n",
      "lowest valid loss = tensor(3.5498, device='cuda:0')\n",
      "learning rate = 9e-05\n",
      "lowest valid loss = tensor(2.8143, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# tuning hyperparameter for Adam\n",
    "\n",
    "learning_rate = [0.00001, 0.00002, 0.00003, 0.00004, 0.00005, 0.00006, 0.00007, 0.00008, 0.00009]\n",
    "for lr in learning_rate:\n",
    "    model_1 = torchvision.models.resnet50(pretrained=True)\n",
    "    fc_features = model_1.fc.in_features\n",
    "    model_1.fc = torch.nn.Linear(fc_features, 4)\n",
    "    model_1 = model_1.to(device)\n",
    "    optimizer = torch.optim.Adam(model_1.parameters(), lr=lr, weight_decay = 0)\n",
    "    print('learning rate =', lr)\n",
    "    train(model_1, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PL2KnzYlvnya",
    "outputId": "3fda3e49-9f93-46c6-f160-b1e5da331bb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 146 test images: 80 %\n",
      "Confusion Matrix :\n",
      "[[ 6  0  1  2]\n",
      " [ 0 27  4 11]\n",
      " [ 0  4 37  2]\n",
      " [ 0  3  2 47]]\n",
      "Per-class Accuracy : [0.66666667 0.64285714 0.86046512 0.90384615]\n"
     ]
    }
   ],
   "source": [
    "# 選擇使用Adam, learning rate = 0.00005\n",
    "model_1 = torchvision.models.resnet50(pretrained=True)\n",
    "fc_features = model_1.fc.in_features\n",
    "model_1.fc = torch.nn.Linear(fc_features, 4)\n",
    "model_1 = model_1.to(device)\n",
    "optimizer = torch.optim.Adam(model_1.parameters(), lr=0.00005, weight_decay = 0)\n",
    "train_test(model_1, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jxAbrdv_Q_XR"
   },
   "source": [
    "Per-class Accuracy: jacket > coat > blazer > cardigan\n",
    "\n",
    "原先預期: jacket > coat > cardigan > blazer\n",
    "\n",
    "原先預期cardigan的準確率應該會比blazer高，會有這樣的結果可能是因為cardigan的valid和test中資料的相似程度較高；而blazer的變化較多，test裡在train和valid沒看過的資料數量較多。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNTTGLuCT1m9"
   },
   "source": [
    "# Q3. pretrained=True + 只調整最後一層Fully Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JMijnX_Ey21g",
    "outputId": "cd5a1fb2-a81c-4a74-eef1-336757a465f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate = 0.001\n",
      "lowest valid loss = tensor(5.0875, device='cuda:0')\n",
      "learning rate = 0.005\n",
      "lowest valid loss = tensor(4.8014, device='cuda:0')\n",
      "learning rate = 0.009\n",
      "lowest valid loss = tensor(4.6584, device='cuda:0')\n",
      "learning rate = 0.01\n",
      "lowest valid loss = tensor(4.2978, device='cuda:0')\n",
      "learning rate = 0.05\n",
      "lowest valid loss = tensor(25.6281, device='cuda:0')\n",
      "learning rate = 0.09\n",
      "lowest valid loss = tensor(40.6288, device='cuda:0')\n",
      "learning rate = 0.1\n",
      "lowest valid loss = tensor(32.9138, device='cuda:0')\n",
      "learning rate = 0.5\n",
      "lowest valid loss = tensor(151.5327, device='cuda:0')\n",
      "learning rate = 0.9\n",
      "lowest valid loss = tensor(223.1741, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# tuning hyperparameter for SGD\n",
    "\n",
    "learning_rate = [0.001, 0.005, 0.009, 0.01, 0.05, 0.09, 0.1, 0.5, 0.9]\n",
    "for lr in learning_rate:\n",
    "    model_2 = torchvision.models.resnet50(pretrained=True)\n",
    "    \n",
    "    # 固定除了最後一層以外的其他權重\n",
    "    for para in model_2.parameters():\n",
    "        para.requires_grad=False\n",
    "        \n",
    "    fc_features = model_2.fc.in_features\n",
    "    model_2.fc = torch.nn.Linear(fc_features, 4)\n",
    "    model_2 = model_2.to(device) \n",
    "\n",
    "    optimizer = torch.optim.SGD(model_2.fc.parameters(), lr=lr)\n",
    "    print('learning rate =', lr)\n",
    "    train(model_2, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xrMywlT_WBCV",
    "outputId": "f18a8447-925c-43f8-ec18-3401a2c927fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate = 2e-05\n",
      "lowest valid loss = tensor(5.2111, device='cuda:0')\n",
      "learning rate = 9e-05\n",
      "lowest valid loss = tensor(4.8201, device='cuda:0')\n",
      "learning rate = 0.0001\n",
      "lowest valid loss = tensor(4.8929, device='cuda:0')\n",
      "learning rate = 0.0005\n",
      "lowest valid loss = tensor(4.0600, device='cuda:0')\n",
      "learning rate = 0.0009\n",
      "lowest valid loss = tensor(4.4463, device='cuda:0')\n",
      "learning rate = 0.001\n",
      "lowest valid loss = tensor(4.7305, device='cuda:0')\n",
      "learning rate = 0.005\n",
      "lowest valid loss = tensor(4.4730, device='cuda:0')\n",
      "learning rate = 0.009\n",
      "lowest valid loss = tensor(4.6439, device='cuda:0')\n",
      "learning rate = 0.1\n",
      "lowest valid loss = tensor(25.7237, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# tuning hyperparameter for Adam\n",
    "\n",
    "learning_rate = [0.00002, 0.00009, 0.0001, 0.0005, 0.0009, 0.001, 0.005, 0.009, 0.1]\n",
    "for lr in learning_rate:\n",
    "    model_2 = torchvision.models.resnet50(pretrained=True)\n",
    "    # 固定除了最後一層以外的其他權重\n",
    "    for para in model_2.parameters():\n",
    "        para.requires_grad=False\n",
    "\n",
    "    fc_features = model_2.fc.in_features\n",
    "    model_2.fc = torch.nn.Linear(fc_features, 4)\n",
    "    model_2 = model_2.to(device) \n",
    "\n",
    "    optimizer = torch.optim.Adam(model_2.fc.parameters(), lr=lr)\n",
    "    print('learning rate =', lr)\n",
    "    train(model_2, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iYlFvMJwW3FG",
    "outputId": "9d44aa31-6eb8-4361-dc64-37fa756d441b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 146 test images: 56 %\n",
      "Confusion Matrix :\n",
      "[[ 0  0  1  8]\n",
      " [ 0 16  3 23]\n",
      " [ 0  4 19 20]\n",
      " [ 1  1  2 48]]\n",
      "Per-class Accuracy : [0.         0.38095238 0.44186047 0.92307692]\n"
     ]
    }
   ],
   "source": [
    "# 選擇使用Adam, learning rate = 0.0005\n",
    "model_2 = torchvision.models.resnet50(pretrained=True)\n",
    "\n",
    "# 固定除了最後一層以外的其他權重\n",
    "for para in model_2.parameters():\n",
    "    para.requires_grad=False\n",
    "\n",
    "fc_features = model_2.fc.in_features\n",
    "model_2.fc = torch.nn.Linear(fc_features, 4)\n",
    "model_2 = model_2.to(device) \n",
    "\n",
    "optimizer = torch.optim.Adam(model_2.parameters(), lr=0.0005, weight_decay = 0)\n",
    "train_test(model_2, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pQ_T3mtcgwQr"
   },
   "source": [
    "# Q4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ajcHfWbzgzXX",
    "outputId": "e39b750c-6e3b-4d3b-8dd0-6ec84fded7f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate = 5e-05\n",
      "lowest valid loss = tensor(5.0631, device='cuda:0')\n",
      "learning rate = 9e-05\n",
      "lowest valid loss = tensor(5.2436, device='cuda:0')\n",
      "learning rate = 0.0001\n",
      "lowest valid loss = tensor(5.1613, device='cuda:0')\n",
      "learning rate = 0.0005\n",
      "lowest valid loss = tensor(5.0577, device='cuda:0')\n",
      "learning rate = 0.0006\n",
      "lowest valid loss = tensor(5.2493, device='cuda:0')\n",
      "learning rate = 0.0007\n",
      "lowest valid loss = tensor(5.0992, device='cuda:0')\n",
      "learning rate = 0.0008\n",
      "lowest valid loss = tensor(5.2202, device='cuda:0')\n",
      "learning rate = 0.0009\n",
      "lowest valid loss = tensor(5.1644, device='cuda:0')\n",
      "learning rate = 0.001\n",
      "lowest valid loss = tensor(5.2797, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# tuning hyperparameter for SGD\n",
    "\n",
    "learning_rate = [0.00005, 0.00009, 0.0001, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009, 0.001]\n",
    "for lr in learning_rate:\n",
    "    model_3 = torchvision.models.resnet50(pretrained=False)\n",
    "    fc_features = model_3.fc.in_features\n",
    "    model_3.fc = torch.nn.Linear(fc_features, 4)\n",
    "    model_3 = model_3.to(device)\n",
    "    optimizer = torch.optim.SGD(model_3.parameters(), lr=lr)\n",
    "    print('learning rate =', lr)\n",
    "    train(model_3, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OlcVmusag2Ix",
    "outputId": "11eff8ea-2ac8-44fa-970f-1b40c88ae78e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate = 1e-05\n",
      "lowest valid loss = tensor(5.2601, device='cuda:0')\n",
      "learning rate = 2e-05\n",
      "lowest valid loss = tensor(5.1548, device='cuda:0')\n",
      "learning rate = 3e-05\n",
      "lowest valid loss = tensor(5.1500, device='cuda:0')\n",
      "learning rate = 4e-05\n",
      "lowest valid loss = tensor(5.2977, device='cuda:0')\n",
      "learning rate = 5e-05\n",
      "lowest valid loss = tensor(5.0238, device='cuda:0')\n",
      "learning rate = 6e-05\n",
      "lowest valid loss = tensor(5.4344, device='cuda:0')\n",
      "learning rate = 7e-05\n",
      "lowest valid loss = tensor(5.5510, device='cuda:0')\n",
      "learning rate = 8e-05\n",
      "lowest valid loss = tensor(5.1449, device='cuda:0')\n",
      "learning rate = 9e-05\n",
      "lowest valid loss = tensor(4.8705, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# tuning hyperparameter for Adam\n",
    "\n",
    "learning_rate = [0.00001, 0.00002, 0.00003, 0.00004, 0.00005, 0.00006, 0.00007, 0.00008, 0.00009]\n",
    "for lr in learning_rate:\n",
    "    model_3 = torchvision.models.resnet50(pretrained=False)\n",
    "    fc_features = model_3.fc.in_features\n",
    "    model_3.fc = torch.nn.Linear(fc_features, 4)\n",
    "    model_3 = model_3.to(device)\n",
    "    optimizer = torch.optim.Adam(model_3.parameters(), lr=lr)\n",
    "    print('learning rate =', lr)\n",
    "    train(model_3, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3RCubaHEkau-",
    "outputId": "ad3a2741-6871-4caf-ce84-f84eb034ef17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 146 test images: 41 %\n",
      "Confusion Matrix :\n",
      "[[ 0  2  1  6]\n",
      " [ 0 19  1 22]\n",
      " [ 0 17  1 25]\n",
      " [ 0 12  0 40]]\n",
      "Per-class Accuracy : [0.         0.45238095 0.02325581 0.76923077]\n"
     ]
    }
   ],
   "source": [
    "# 選擇使用Adam, learning rate = 0.0009\n",
    "model_3 = torchvision.models.resnet50(pretrained=False)\n",
    "fc_features = model_3.fc.in_features\n",
    "model_3.fc = torch.nn.Linear(fc_features, 4)\n",
    "model_3 = model_3.to(device)\n",
    "optimizer = torch.optim.Adam(model_3.parameters(), lr=0.0009)\n",
    "train_test(model_3, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kHf-2nU7sxDX"
   },
   "source": [
    "# Q5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ULoNmHG6sy-g"
   },
   "source": [
    "預測能力: Q2 > Q3 > Q4\n",
    "\n",
    "- 比較Q2和Q3的結果: Q2和Q3的差別在於是否有調整除了最後一層的Fully Connected Layer。\n",
    "  可以發現如果訓練的過程指訓練Fully Connected Layer，對於預測能力的提升非常有限，即使有使用Pretrained仍然無法有好的預測能力。\n",
    "  \n",
    "- 比較Q2和Q4的結果: Q2和Q4的差別在於是否使用Pretrained。\n",
    "  從結果來看，是否有使用Pretrained對模型的準確率影響非常大，沒有使用跟有使用之間的準確率差了將近40％。\n",
    " \n",
    "- 綜合三題的結果來看，如果想要模型的表現較佳，不管是Pretrained或者是訓練所有層數的參數都是必要的。\n",
    "  而且是否有Pretrained對模型的影響比只訓練部分層的參數對模型的影響更大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hw5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
